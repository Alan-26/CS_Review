# 事务



## 一、什么是事务？

我们先来看一个例子：A要转1000块钱给B，这个转账中两个主要的操作就是：A的减少1000块钱，B增加1000块钱。但是万一在这两个操作之间发生了一些不可抗力因素，比如银行系统崩溃，导致了A的账户减少了1000块钱，而B却没有收到这1000块钱，这很明显是不合理的。所以，事务就是保证这两个主要的操作，要么都成功，要么都失败。

**简单来说，事务就是逻辑上的一组操作，要么都执行，要么都不执行。**



## 二、四大特性（ACID）

那么一旦一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性：

![image.png](https://gitee.com/lgaaip/img/raw/master/20210225102223.png)

1. **原子性（Atomicity）：** **事务包含的所有操作要么全部成功，要么失败回滚，不起作用**
2. **一致性（Consistency）：** **执行事务前后，数据都保持一致，多个事务对统一数据读取的结果是相同的**
3. **隔离性（Isolation）：** **并发访问数据库时，一个用户的事务不被其他事务锁干扰，各个并发事务是相互独立的**
4. **持久性（Durability）：** **一个事务被提交之后，它对数据库的改变是持久的，即使数据库发生故障也不应该对其有任何影响**



其他性质都很容易就搞懂了，顾名思义，但是隔离性，它是保证了每个事务之间的相互独立的。但是，在现在高并发的环境下，每个事务之间的干扰真的不存在吗？下面我们就来看一下，并发事务下带来了什么问题？

## 三、并发事务带来了什么问题？

在应用程序中，多个事务并发运行，经常会对相同的数据进行操作，这是正常的，但是会带来以下问题：

### 脏读

- <font color='orange'>**脏读（Dirty read）：**</font>**读到未提交的数据**

  在不同的事务中，当前事务可以读到另外事务未提交的数据。

  当一个事务正在访问数据库并且对数据进行修改时，在它修改的过程中，还没有提交修改后的数据，此时有另外一个事务去读取了这个数据，然后去使用了这个数据。这个数据是修改之前的，那么另外一个事务读到的数据就是“脏数据”，依据“脏数据”进行的操作可能是不正确的

### 丢失修改

- <font color='orange'>**丢失修改（Lost to modify）：**</font>**丢失了某个事务修改后的结果**

  指在一个事务读取一个数据时，另外一个事务也访问了数据，那么在第一个事务修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务修改后的结果将会被丢失掉，因此称为丢失修改。例如：事务1读取了某表中的数据A=20，然后事务1修改A=A-2，事务2也修改A=A-1，最终的结果将是18而不是19，事务1的修改被丢失。（<font color='cornflowerblue'>这种情况下在数据库中一般不会出现，因为对于行DML操作，需要对行或其他粗粒度级别的对象加锁。</font>）事务2并不能对数据A进行更新操作，其会被阻塞，知道事务1的提交。

  > 但是，虽然数据库能阻止丢失更新问题的产生，但是还有现实应用中还有另外一个逻辑意义上的丢失修改：
  >
  > 1) 事务A查询一行数据，放到本地内存中，并显示给终端用户U1
  >
  > 2) 事务B也查询这行数据，然后显示给终端用户U2
  >
  > 3) U1修改这行数据，更新数据并提交
  >
  > 4) U2修改这行数据，更新数据并提交

  <font color='green'>我们可以发现，U1的这个更新操作丢失了，这是一件很恐怖的事情。</font>

  你想，假设技术高手小A有一个银行账户中有1000块钱，在某个月黑风高的晚上，他发现了这一漏洞，此时他利用两个网上银行客户端，他用第一个客户端转走了999块钱，因为网络和数据库的关系，这个时候需要等待。他利用这个时间差，使用另外一个客户端转账1元，如果这两次操作都成功了，那么现在他账户中就还剩下999块钱，在第一次转999块钱的操作并没有更新，但是另外的账户却受到了999块钱，这会导致他白嫖999块钱。所以这个问题还是得在数据库层面进行解决，避免这些情况的发生。


### 不可重复度

- <font color='orange'>**不可重复读（Unrepeatableread）：**</font>**一次事务中读同一个数据结果不一致**

  指在一个事务内多次读同一数据。在这个事务还没有结束时，另外一个事务也访问了该数据。那么第一个事务中两次读数据之间，由于第二个事务的修改导致第一个事务两次读取数据可能不一样。这就发生了在同一个事务内两个读取到的数据不一样，因此称为不可重复读。

  > 例子：事务A第一次读取表中的数据为1，此时有另外的事务B对表进行了插入操作，插入了2。在事务B提交之前，事务A读取的数据还是1，没有发生脏读，当事务B提交时，事务A读取的数据变成了1，2。
  >
  > <font color='cornflowerblue'>这个例子的前提是，事务开始之前，隔离级别为：读已提交</font>

### 幻读

- <font color='orange'>**幻读（Phantom read）：**</font>**一个事务读同个表或者查询时，结果多了几行。**

  幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另外一个并发事务（T2）插入了一些数据。然后在随后的查询中，第一个事务（T1）就会发现多了一些原来不存在的记录，就好像发生了幻觉一样，所以称为幻读。

  

`不可重复读`与`脏读`的区别：

- `脏读`是读到了未提交的数据，而`不可重复度`恰巧是读到了已提交的数据，都违反了数据库事务**一致性**的要求。

`不可重复读`与`幻读`的区别：

- `不可重复读的重点是修改`，比如多次读取同一条记录然后发现其中一些值被修改；
- `幻读的重点在于新增或者删除`，比如多次读取一条记录发现记录增加或者减少了。



为了解决上面出现的问题，MySQL数据库给我们提供了四种隔离级别。



## 四、隔离级别

SQL标准定义了四个隔离级别：

- <font color='orange'>**READ-UNCOMMITTED(读取未提交)：**</font>最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读，幻读或不可重复读。**
- <font color='orange'>**READ-COMMITTED(读取已提交):** </font>允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生。**
- <font color='orange'>**REPEATABLE-READ(可重复读):** </font>对于同一字段的多次读取结果是一致的，**除非数据是被本身事务自己修改的，可以阻止脏读和不可重复读，但是幻读仍有可能发生**
- <font color='orange'>**SERIALIZABLE(可串行化)：**</font>强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。**该级别可以防止脏读，不可重复读以及幻读。**

用表格表示比较清晰：（√表示存在，×表示不存在）

| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
| :------: | :--: | :--------: | :--: |
| 读未提交 |  √   |     √      |  √   |
| 读已提交 |  ×   |     √      |  √   |
| 可重复读 |  ×   |     ×      |  √   |
| 可串行化 |  ×   |     ×      |  ×   |

那么，MySQL默认的隔离级别是什么呢？

我们通过一个命令来查看一下：

```sql
SELECT @@tx_isolation;
```

![image.png](https://gitee.com/lgaaip/img/raw/master/20210225105137.png)

我们可以看到MySQL的默认隔离级别是**REPEATABLE-READ（可重读）**。

> 为什么MySQL的默认隔离级别是可重复读？可重复读不是不能保证幻读吗？

因为MySQL的锁机制中支持行级锁，使用了Next-key Lock锁算法配合REPEATABLE-READ 可重复读可以解决幻读问题，所以MySQL的默认隔离级别是可重复读。

`Tips:`因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) 。

